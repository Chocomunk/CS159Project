{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# import qpth.solvers.dynamic.solve as dynamic_solver\n",
    "# from qpth.util import get_sizes\n",
    "\n",
    "def get_sizes(G, A=None):\n",
    "    if G.dim() == 2:\n",
    "        nineq, nz = G.size()\n",
    "        nBatch = 1\n",
    "    elif G.dim() == 3:\n",
    "        nBatch, nineq, nz = G.size()\n",
    "    if A is not None:\n",
    "        neq = A.size(1) if A.nelement() > 0 else 0\n",
    "    else:\n",
    "        neq = None\n",
    "    # nBatch = batchedTensor.size(0) if batchedTensor is not None else None\n",
    "    return nineq, nz, neq, nBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(H, c, A, b, verbose=0, maxIter=100, dt=0.2):\n",
    "    nineq, nz, neq, nBatch = get_sizes(A)\n",
    "    A_T = torch.transpose(A, -1,1)\n",
    "    H_I = torch.inverse(H)\n",
    "\n",
    "    AH_I = A.matmul(H_I)\n",
    "    D = - AH_I.matmul(A_T)\n",
    "    d = - (b.unsqueeze(2) + AH_I.matmul(c.unsqueeze(2)))\n",
    "\n",
    "    y = torch.zeros(nBatch, nineq, 1)\n",
    "    zeros = torch.zeros(nBatch, nineq, 1)\n",
    "\n",
    "    for _ in range(maxIter):\n",
    "        dy = dt * (D.matmul(y) + d)\n",
    "        dy = torch.max(y + dy, zeros) - y\n",
    "        y.add_(dy)\n",
    "\n",
    "    zhat = - H_I.matmul(c.unsqueeze(2) + A_T.matmul(y))\n",
    "    slacks = b.unsqueeze(2) - A.matmul(zhat)\n",
    "    \n",
    "    return zhat, y, slacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-30., -30.]])\ntensor([[ 2.9167, 17.5000,  5.0000,  5.0000,  0.0000,  0.0000]])\ntensor([[[ 0.4167, -1.0000],\n         [ 2.5000,  1.0000],\n         [-1.0000,  0.0000],\n         [ 0.0000,  1.0000],\n         [-1.0000,  0.0000],\n         [ 0.0000, -1.0000]]])\ntensor([[[2., 1.],\n         [1., 2.]]])\n"
    }
   ],
   "source": [
    "# Example data from: https://www.sciencedirect.com/science/article/pii/S0307904X1000380X#f0010\n",
    "\n",
    "c = torch.tensor([-30, -30], dtype=torch.float).unsqueeze(0)\n",
    "b = torch.tensor([35/12, 35/2, 5, 5, 0, 0], dtype=torch.float).unsqueeze(0)\n",
    "A = torch.tensor([\n",
    "    [5/12, -1],\n",
    "    [5/2, 1],\n",
    "    [-1, 0],\n",
    "    [0, 1],\n",
    "    [-1, 0],\n",
    "    [0, -1]\n",
    "], dtype=torch.float).unsqueeze(0)\n",
    "H = torch.tensor([[2,1],[1,2]], dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "print(c)\n",
    "print(b)\n",
    "print(A)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[5.0000],\n         [5.0000]]])\ntensor([[[0.0000],\n         [6.0000],\n         [0.0000],\n         [9.0000],\n         [0.0000],\n         [0.0000]]])\ntensor([[[ 5.8333e+00],\n         [-3.8147e-06],\n         [ 1.0000e+01],\n         [-4.7684e-06],\n         [ 5.0000e+00],\n         [ 5.0000e+00]]])\n"
    }
   ],
   "source": [
    "zhat, y, slacks = forward(H, c, A, b, maxIter=100)\n",
    "\n",
    "print(zhat)\n",
    "print(y)\n",
    "print(slacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitcs159conda5739f4b666d44eb9afad7229d8e1fa2f",
   "display_name": "Python 3.8.2 64-bit ('cs159': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
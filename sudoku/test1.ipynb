{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN ALL CELLS AND CHECK THE RESULTS AT THE BOTTOM\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "try: import setGPU\n",
    "except ImportError: pass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "\n",
    "import models\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"work/2.optnetIneq.Qpenalty=0.1.nineq=100/latest.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/{}/features.pt'.format(2), 'rb') as f:\n",
    "    testX = torch.load(f)\n",
    "with open('data/{}/labels.pt'.format(2), 'rb') as f:\n",
    "    testY = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeErr(pred):\n",
    "    batchSz = pred.size(0)\n",
    "    nsq = int(pred.size(1))\n",
    "    n = int(np.sqrt(nsq))\n",
    "    s = (nsq-1)*nsq//2 # 0 + 1 + ... + n^2-1\n",
    "    I = torch.max(pred, 3)[1].squeeze().view(batchSz, nsq, nsq)\n",
    "\n",
    "    def invalidGroups(x):\n",
    "        valid = (x.min(1)[0] == 0)\n",
    "        valid *= (x.max(1)[0] == nsq-1)\n",
    "        valid *= (x.sum(1) == s)\n",
    "        return ~valid\n",
    "\n",
    "    boardCorrect = torch.ones(batchSz).type_as(pred)\n",
    "    for j in range(nsq):\n",
    "        # Check the jth row and column.\n",
    "        boardCorrect[invalidGroups(I[:,j,:])] = 0\n",
    "        boardCorrect[invalidGroups(I[:,:,j])] = 0\n",
    "\n",
    "        # Check the jth block.\n",
    "        row, col = n*(j // n), n*(j % n)\n",
    "        M = invalidGroups(I[:,row:row+n,col:col+n].contiguous().view(batchSz,-1))\n",
    "        boardCorrect[M] = 0\n",
    "\n",
    "        if boardCorrect.sum() == 0:\n",
    "            return batchSz\n",
    "\n",
    "    return batchSz-boardCorrect.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, batchSz = 100):\n",
    "    test_loss = 0\n",
    "    batch_data_t = torch.FloatTensor(batchSz, testX.size(1), testX.size(2), testX.size(3))\n",
    "    batch_targets_t = torch.FloatTensor(batchSz, testY.size(1), testX.size(2), testX.size(3))\n",
    "\n",
    "    batch_data = Variable(batch_data_t)\n",
    "    batch_targets = Variable(batch_targets_t)\n",
    "\n",
    "    nErr = 0\n",
    "    start_time = time.time()\n",
    "    size = testX.size(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, size, batchSz):\n",
    "            print('Testing model: {}/{}'.format(i, size), end='\\r')\n",
    "            batch_data.data[:] = testX[i:i+batchSz]\n",
    "            batch_targets.data[:] = testY[i:i+batchSz]\n",
    "            output = model(batch_data)\n",
    "            test_loss += nn.MSELoss()(output, batch_targets)\n",
    "            nErr += computeErr(output.data)\n",
    "\n",
    "    dt = time.time() - start_time\n",
    "    \n",
    "    nBatches = size/batchSz\n",
    "    test_loss = test_loss.item()/nBatches\n",
    "    test_err = nErr/size\n",
    "    print('TEST SET RESULTS:' + ' ' * 20)\n",
    "    print('Average loss: {:.4f}'.format(test_loss))\n",
    "    print('Err: {:.4f}'.format(test_err))\n",
    "    print(f'nErr: {nErr}')\n",
    "    \n",
    "    print(f'Average time per batch: {dt / nBatches}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.DynamicIneq(n=2, Qpenalty=0.1, nineq=100)\n",
    "\n",
    "params = model.named_parameters()\n",
    "params1 = model1.named_parameters()\n",
    "\n",
    "dict_params1 = dict(params1)\n",
    "\n",
    "for name, param in params:\n",
    "    if name in dict_params1:\n",
    "        dict_params1[name].data.copy_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET RESULTS:                    \n",
      "Average loss: 0.0055\n",
      "Err: 0.0030\n",
      "nErr: 3.0\n",
      "Average time per batch: 13.113858509063721\n"
     ]
    }
   ],
   "source": [
    "# THIS TESTS OPTNET\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET RESULTS:                    \n",
      "Average loss: inf\n",
      "Err: 1.0000\n",
      "nErr: 1000\n",
      "Average time per batch: 0.0841663122177124\n"
     ]
    }
   ],
   "source": [
    "# THIS TESTS DYNAMIC\n",
    "test(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
